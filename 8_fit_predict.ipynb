{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c53c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "folder = 'd:/git/project1/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b783b4db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data = pd.read_csv(f'{folder}/last_hs_tweets_ch1_0.csv')\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50fdec58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>change_1_direct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807251</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807252</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807253</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807254</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807255</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>807256 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        change_1_direct\n",
       "0                   1.0\n",
       "1                   1.0\n",
       "2                   1.0\n",
       "3                   1.0\n",
       "4                   1.0\n",
       "...                 ...\n",
       "807251              0.0\n",
       "807252              0.0\n",
       "807253              1.0\n",
       "807254              0.0\n",
       "807255              0.0\n",
       "\n",
       "[807256 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cols = ['date', 'change_1_direct', 'change_3_direct', 'change_7_direct', 'change_30_direct', 'change_90_direct']\n",
    "cols = ['change_1_direct']\n",
    "changes = pd.read_csv(f'{folder}/tweets_change_padded.csv', usecols=cols)\n",
    "changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62bf1ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parts(name, start, end):\n",
    "    count = 1000\n",
    "    data = pd.DataFrame(None)\n",
    "    \n",
    "    for num in range(start, end):\n",
    "        start_index = num*count\n",
    "        end_index = start_index + count - 1\n",
    "        data_part = pd.read_csv(f'{folder}/{name}_{start_index}.csv', usecols=range(770))\n",
    "        df = pd.DataFrame(np.array(changes.loc[start_index:end_index, cols]), columns=cols)\n",
    "        union = pd.concat([data_part, df], axis=1)\n",
    "        \n",
    "        data = data.append(union, sort=False, ignore_index=True)\n",
    "    #res_table.to_csv(f'{folder}\\cls_direct30_{num}.csv', index=False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "327e2cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 54s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>retweet</th>\n",
       "      <th>time</th>\n",
       "      <th>change_1_direct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.417784</td>\n",
       "      <td>-0.159195</td>\n",
       "      <td>0.049453</td>\n",
       "      <td>-0.019281</td>\n",
       "      <td>-0.143110</td>\n",
       "      <td>-0.371498</td>\n",
       "      <td>0.205367</td>\n",
       "      <td>0.469781</td>\n",
       "      <td>-0.180655</td>\n",
       "      <td>0.086964</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.729234</td>\n",
       "      <td>0.435944</td>\n",
       "      <td>0.665804</td>\n",
       "      <td>-0.087694</td>\n",
       "      <td>-0.412030</td>\n",
       "      <td>-0.138853</td>\n",
       "      <td>0.688434</td>\n",
       "      <td>7.0</td>\n",
       "      <td>45736</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.154517</td>\n",
       "      <td>-0.305308</td>\n",
       "      <td>0.424442</td>\n",
       "      <td>-0.002735</td>\n",
       "      <td>-0.164633</td>\n",
       "      <td>-0.258918</td>\n",
       "      <td>0.182587</td>\n",
       "      <td>0.578418</td>\n",
       "      <td>-0.027604</td>\n",
       "      <td>-0.099199</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.320284</td>\n",
       "      <td>0.295116</td>\n",
       "      <td>0.262499</td>\n",
       "      <td>-0.145339</td>\n",
       "      <td>-0.557404</td>\n",
       "      <td>0.249221</td>\n",
       "      <td>0.425408</td>\n",
       "      <td>68.0</td>\n",
       "      <td>29586</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000540</td>\n",
       "      <td>-0.246681</td>\n",
       "      <td>0.059547</td>\n",
       "      <td>-0.272320</td>\n",
       "      <td>-0.436857</td>\n",
       "      <td>-0.234840</td>\n",
       "      <td>0.253098</td>\n",
       "      <td>0.908152</td>\n",
       "      <td>0.024199</td>\n",
       "      <td>-0.300646</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.264831</td>\n",
       "      <td>0.263115</td>\n",
       "      <td>-0.038263</td>\n",
       "      <td>-0.094645</td>\n",
       "      <td>-0.439378</td>\n",
       "      <td>0.201307</td>\n",
       "      <td>0.520169</td>\n",
       "      <td>4.0</td>\n",
       "      <td>75329</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.097781</td>\n",
       "      <td>-0.031261</td>\n",
       "      <td>0.059328</td>\n",
       "      <td>0.297294</td>\n",
       "      <td>-0.162170</td>\n",
       "      <td>-0.514269</td>\n",
       "      <td>0.549677</td>\n",
       "      <td>0.571328</td>\n",
       "      <td>-0.091938</td>\n",
       "      <td>-0.208955</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.419469</td>\n",
       "      <td>0.434312</td>\n",
       "      <td>0.067487</td>\n",
       "      <td>-0.082194</td>\n",
       "      <td>-0.356370</td>\n",
       "      <td>-0.015842</td>\n",
       "      <td>0.434768</td>\n",
       "      <td>85.0</td>\n",
       "      <td>63389</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.405389</td>\n",
       "      <td>-0.342308</td>\n",
       "      <td>0.293121</td>\n",
       "      <td>0.140589</td>\n",
       "      <td>-0.473491</td>\n",
       "      <td>-0.248678</td>\n",
       "      <td>0.463207</td>\n",
       "      <td>0.182642</td>\n",
       "      <td>-0.361493</td>\n",
       "      <td>-0.363156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019985</td>\n",
       "      <td>0.224207</td>\n",
       "      <td>0.206847</td>\n",
       "      <td>-0.075846</td>\n",
       "      <td>-0.508190</td>\n",
       "      <td>0.142789</td>\n",
       "      <td>0.311084</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5857</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>-0.190831</td>\n",
       "      <td>0.111325</td>\n",
       "      <td>-0.007943</td>\n",
       "      <td>0.209162</td>\n",
       "      <td>-0.204160</td>\n",
       "      <td>-0.366423</td>\n",
       "      <td>0.579954</td>\n",
       "      <td>0.380756</td>\n",
       "      <td>-0.227440</td>\n",
       "      <td>-0.128254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072001</td>\n",
       "      <td>0.233051</td>\n",
       "      <td>0.408162</td>\n",
       "      <td>-0.304246</td>\n",
       "      <td>-0.348964</td>\n",
       "      <td>0.134679</td>\n",
       "      <td>0.743559</td>\n",
       "      <td>2.0</td>\n",
       "      <td>79202</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0.176868</td>\n",
       "      <td>-0.362221</td>\n",
       "      <td>0.074079</td>\n",
       "      <td>0.066585</td>\n",
       "      <td>-0.009989</td>\n",
       "      <td>-0.425526</td>\n",
       "      <td>0.353912</td>\n",
       "      <td>0.466246</td>\n",
       "      <td>-0.058196</td>\n",
       "      <td>-0.264946</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.420290</td>\n",
       "      <td>0.151437</td>\n",
       "      <td>0.422059</td>\n",
       "      <td>-0.445005</td>\n",
       "      <td>-0.381655</td>\n",
       "      <td>0.032492</td>\n",
       "      <td>0.645175</td>\n",
       "      <td>2.0</td>\n",
       "      <td>78964</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>-0.086020</td>\n",
       "      <td>-0.137973</td>\n",
       "      <td>-0.054955</td>\n",
       "      <td>0.038759</td>\n",
       "      <td>-0.090016</td>\n",
       "      <td>-0.238761</td>\n",
       "      <td>0.160697</td>\n",
       "      <td>0.416090</td>\n",
       "      <td>-0.034831</td>\n",
       "      <td>-0.027933</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216983</td>\n",
       "      <td>0.200104</td>\n",
       "      <td>0.159398</td>\n",
       "      <td>-0.170248</td>\n",
       "      <td>-0.418308</td>\n",
       "      <td>0.369494</td>\n",
       "      <td>0.665510</td>\n",
       "      <td>2.0</td>\n",
       "      <td>78625</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0.168974</td>\n",
       "      <td>-0.353340</td>\n",
       "      <td>0.055526</td>\n",
       "      <td>0.063732</td>\n",
       "      <td>-0.014129</td>\n",
       "      <td>-0.439472</td>\n",
       "      <td>0.354419</td>\n",
       "      <td>0.485233</td>\n",
       "      <td>-0.063634</td>\n",
       "      <td>-0.269874</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.418296</td>\n",
       "      <td>0.141576</td>\n",
       "      <td>0.423993</td>\n",
       "      <td>-0.450304</td>\n",
       "      <td>-0.378812</td>\n",
       "      <td>0.031307</td>\n",
       "      <td>0.658095</td>\n",
       "      <td>2.0</td>\n",
       "      <td>78343</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>-0.102992</td>\n",
       "      <td>-0.180803</td>\n",
       "      <td>0.003302</td>\n",
       "      <td>0.071570</td>\n",
       "      <td>-0.107520</td>\n",
       "      <td>-0.214042</td>\n",
       "      <td>0.107835</td>\n",
       "      <td>0.382630</td>\n",
       "      <td>-0.072017</td>\n",
       "      <td>-0.019725</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.210459</td>\n",
       "      <td>0.134150</td>\n",
       "      <td>0.186101</td>\n",
       "      <td>-0.163524</td>\n",
       "      <td>-0.406920</td>\n",
       "      <td>0.389161</td>\n",
       "      <td>0.646289</td>\n",
       "      <td>2.0</td>\n",
       "      <td>78003</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -0.417784 -0.159195  0.049453 -0.019281 -0.143110 -0.371498  0.205367   \n",
       "1     -0.154517 -0.305308  0.424442 -0.002735 -0.164633 -0.258918  0.182587   \n",
       "2      0.000540 -0.246681  0.059547 -0.272320 -0.436857 -0.234840  0.253098   \n",
       "3      0.097781 -0.031261  0.059328  0.297294 -0.162170 -0.514269  0.549677   \n",
       "4     -0.405389 -0.342308  0.293121  0.140589 -0.473491 -0.248678  0.463207   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "99995 -0.190831  0.111325 -0.007943  0.209162 -0.204160 -0.366423  0.579954   \n",
       "99996  0.176868 -0.362221  0.074079  0.066585 -0.009989 -0.425526  0.353912   \n",
       "99997 -0.086020 -0.137973 -0.054955  0.038759 -0.090016 -0.238761  0.160697   \n",
       "99998  0.168974 -0.353340  0.055526  0.063732 -0.014129 -0.439472  0.354419   \n",
       "99999 -0.102992 -0.180803  0.003302  0.071570 -0.107520 -0.214042  0.107835   \n",
       "\n",
       "              7         8         9  ...       761       762       763  \\\n",
       "0      0.469781 -0.180655  0.086964  ... -0.729234  0.435944  0.665804   \n",
       "1      0.578418 -0.027604 -0.099199  ... -0.320284  0.295116  0.262499   \n",
       "2      0.908152  0.024199 -0.300646  ... -0.264831  0.263115 -0.038263   \n",
       "3      0.571328 -0.091938 -0.208955  ... -0.419469  0.434312  0.067487   \n",
       "4      0.182642 -0.361493 -0.363156  ... -0.019985  0.224207  0.206847   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "99995  0.380756 -0.227440 -0.128254  ... -0.072001  0.233051  0.408162   \n",
       "99996  0.466246 -0.058196 -0.264946  ... -0.420290  0.151437  0.422059   \n",
       "99997  0.416090 -0.034831 -0.027933  ... -0.216983  0.200104  0.159398   \n",
       "99998  0.485233 -0.063634 -0.269874  ... -0.418296  0.141576  0.423993   \n",
       "99999  0.382630 -0.072017 -0.019725  ... -0.210459  0.134150  0.186101   \n",
       "\n",
       "            764       765       766       767  retweet   time  change_1_direct  \n",
       "0     -0.087694 -0.412030 -0.138853  0.688434      7.0  45736              1.0  \n",
       "1     -0.145339 -0.557404  0.249221  0.425408     68.0  29586              1.0  \n",
       "2     -0.094645 -0.439378  0.201307  0.520169      4.0  75329              1.0  \n",
       "3     -0.082194 -0.356370 -0.015842  0.434768     85.0  63389              1.0  \n",
       "4     -0.075846 -0.508190  0.142789  0.311084      8.0   5857              1.0  \n",
       "...         ...       ...       ...       ...      ...    ...              ...  \n",
       "99995 -0.304246 -0.348964  0.134679  0.743559      2.0  79202              0.0  \n",
       "99996 -0.445005 -0.381655  0.032492  0.645175      2.0  78964              1.0  \n",
       "99997 -0.170248 -0.418308  0.369494  0.665510      2.0  78625              1.0  \n",
       "99998 -0.450304 -0.378812  0.031307  0.658095      2.0  78343              1.0  \n",
       "99999 -0.163524 -0.406920  0.389161  0.646289      2.0  78003              1.0  \n",
       "\n",
       "[100000 rows x 771 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "raw_data = load_parts('last_hs_tweets_ch', 0, 100)\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3839d12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181240.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['retweet'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02b1c500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max = 181240\n",
    "raw_data['retweet'] = raw_data['retweet'].apply(lambda x: (x - max/2)/(max/2))\n",
    "raw_data['retweet'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0297b312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86399"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['time'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1df2f7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0092790697674419"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max = 86000\n",
    "raw_data['time'] = raw_data['time'].apply(lambda x: (x - max/2)/(max/2))\n",
    "raw_data['time'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85fbd3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1559934000.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54ac09f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1380567600.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "333e1adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min = 1380567600\n",
    "max = 1559934000\n",
    "raw_data['date'] = raw_data['date'].apply(lambda x: (x - min)/(max-min))\n",
    "raw_data['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82a1cb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07427cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.54 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>retweet</th>\n",
       "      <th>time</th>\n",
       "      <th>change_1_direct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40873</th>\n",
       "      <td>0.154078</td>\n",
       "      <td>-0.201394</td>\n",
       "      <td>0.026564</td>\n",
       "      <td>0.217482</td>\n",
       "      <td>-0.117782</td>\n",
       "      <td>-0.712478</td>\n",
       "      <td>0.040226</td>\n",
       "      <td>0.649390</td>\n",
       "      <td>0.190963</td>\n",
       "      <td>-0.307655</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.607841</td>\n",
       "      <td>0.322955</td>\n",
       "      <td>0.457741</td>\n",
       "      <td>-0.102821</td>\n",
       "      <td>-0.443432</td>\n",
       "      <td>0.124357</td>\n",
       "      <td>0.630489</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30493</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>0.110829</td>\n",
       "      <td>0.087697</td>\n",
       "      <td>0.203372</td>\n",
       "      <td>-0.178707</td>\n",
       "      <td>-0.642821</td>\n",
       "      <td>-0.543686</td>\n",
       "      <td>0.277545</td>\n",
       "      <td>0.589370</td>\n",
       "      <td>-0.150682</td>\n",
       "      <td>-0.450952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.354488</td>\n",
       "      <td>0.312999</td>\n",
       "      <td>0.259520</td>\n",
       "      <td>-0.103768</td>\n",
       "      <td>-0.588483</td>\n",
       "      <td>0.249900</td>\n",
       "      <td>0.225558</td>\n",
       "      <td>21.0</td>\n",
       "      <td>67411</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58367</th>\n",
       "      <td>0.389685</td>\n",
       "      <td>-0.070361</td>\n",
       "      <td>0.226413</td>\n",
       "      <td>0.011184</td>\n",
       "      <td>-0.218933</td>\n",
       "      <td>-0.453032</td>\n",
       "      <td>0.584852</td>\n",
       "      <td>0.535753</td>\n",
       "      <td>-0.016475</td>\n",
       "      <td>-0.470529</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.505246</td>\n",
       "      <td>0.328158</td>\n",
       "      <td>-0.015673</td>\n",
       "      <td>0.022542</td>\n",
       "      <td>-0.277971</td>\n",
       "      <td>0.256051</td>\n",
       "      <td>0.558487</td>\n",
       "      <td>2.0</td>\n",
       "      <td>63557</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26878</th>\n",
       "      <td>-0.166137</td>\n",
       "      <td>-0.135977</td>\n",
       "      <td>0.175625</td>\n",
       "      <td>0.177462</td>\n",
       "      <td>-0.134225</td>\n",
       "      <td>-0.336339</td>\n",
       "      <td>-0.011873</td>\n",
       "      <td>0.453432</td>\n",
       "      <td>-0.134633</td>\n",
       "      <td>-0.255964</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.554123</td>\n",
       "      <td>0.428766</td>\n",
       "      <td>0.516216</td>\n",
       "      <td>-0.469654</td>\n",
       "      <td>-0.421126</td>\n",
       "      <td>0.073560</td>\n",
       "      <td>0.534384</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46775</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11913</th>\n",
       "      <td>-0.161652</td>\n",
       "      <td>-0.316417</td>\n",
       "      <td>0.087562</td>\n",
       "      <td>-0.180851</td>\n",
       "      <td>-0.263479</td>\n",
       "      <td>-0.251145</td>\n",
       "      <td>0.140881</td>\n",
       "      <td>0.424626</td>\n",
       "      <td>-0.035675</td>\n",
       "      <td>-0.417812</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.716426</td>\n",
       "      <td>0.061558</td>\n",
       "      <td>0.553769</td>\n",
       "      <td>-0.220546</td>\n",
       "      <td>-0.231607</td>\n",
       "      <td>-0.058111</td>\n",
       "      <td>0.782034</td>\n",
       "      <td>7.0</td>\n",
       "      <td>82973</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8094</th>\n",
       "      <td>-0.009050</td>\n",
       "      <td>-0.120176</td>\n",
       "      <td>-0.218051</td>\n",
       "      <td>-0.091481</td>\n",
       "      <td>-0.084636</td>\n",
       "      <td>-0.249447</td>\n",
       "      <td>0.164419</td>\n",
       "      <td>0.769991</td>\n",
       "      <td>-0.129390</td>\n",
       "      <td>-0.380851</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.254722</td>\n",
       "      <td>0.109970</td>\n",
       "      <td>0.102325</td>\n",
       "      <td>-0.203718</td>\n",
       "      <td>-0.189995</td>\n",
       "      <td>0.076426</td>\n",
       "      <td>0.542887</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54504</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18064</th>\n",
       "      <td>-0.268845</td>\n",
       "      <td>-0.285695</td>\n",
       "      <td>0.190564</td>\n",
       "      <td>-0.009600</td>\n",
       "      <td>-0.218369</td>\n",
       "      <td>-0.083192</td>\n",
       "      <td>0.098382</td>\n",
       "      <td>0.317847</td>\n",
       "      <td>0.057382</td>\n",
       "      <td>-0.158775</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433835</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.106776</td>\n",
       "      <td>-0.236143</td>\n",
       "      <td>-0.265077</td>\n",
       "      <td>0.033676</td>\n",
       "      <td>0.580178</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60654</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17745</th>\n",
       "      <td>0.209622</td>\n",
       "      <td>-0.083331</td>\n",
       "      <td>0.235984</td>\n",
       "      <td>0.099007</td>\n",
       "      <td>-0.574764</td>\n",
       "      <td>-0.488376</td>\n",
       "      <td>0.100918</td>\n",
       "      <td>0.543892</td>\n",
       "      <td>-0.268854</td>\n",
       "      <td>-0.158150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103803</td>\n",
       "      <td>0.262976</td>\n",
       "      <td>0.063059</td>\n",
       "      <td>-0.095611</td>\n",
       "      <td>-0.310393</td>\n",
       "      <td>0.297672</td>\n",
       "      <td>0.371484</td>\n",
       "      <td>3.0</td>\n",
       "      <td>71564</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62218</th>\n",
       "      <td>-0.404304</td>\n",
       "      <td>0.309166</td>\n",
       "      <td>0.182504</td>\n",
       "      <td>-0.065580</td>\n",
       "      <td>-0.822769</td>\n",
       "      <td>-0.025005</td>\n",
       "      <td>0.732324</td>\n",
       "      <td>-0.050806</td>\n",
       "      <td>-0.079255</td>\n",
       "      <td>-0.318297</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.295160</td>\n",
       "      <td>0.584818</td>\n",
       "      <td>-0.064049</td>\n",
       "      <td>-0.151786</td>\n",
       "      <td>-0.574533</td>\n",
       "      <td>0.430951</td>\n",
       "      <td>0.411983</td>\n",
       "      <td>57.0</td>\n",
       "      <td>38660</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>-0.435416</td>\n",
       "      <td>0.463265</td>\n",
       "      <td>-0.253529</td>\n",
       "      <td>-0.357788</td>\n",
       "      <td>-0.255868</td>\n",
       "      <td>0.528730</td>\n",
       "      <td>0.770660</td>\n",
       "      <td>0.181389</td>\n",
       "      <td>0.393911</td>\n",
       "      <td>-0.556885</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.503047</td>\n",
       "      <td>-0.008470</td>\n",
       "      <td>-0.328027</td>\n",
       "      <td>-0.450504</td>\n",
       "      <td>-0.517881</td>\n",
       "      <td>0.559338</td>\n",
       "      <td>0.039356</td>\n",
       "      <td>11.0</td>\n",
       "      <td>58236</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "40873  0.154078 -0.201394  0.026564  0.217482 -0.117782 -0.712478  0.040226   \n",
       "832    0.110829  0.087697  0.203372 -0.178707 -0.642821 -0.543686  0.277545   \n",
       "58367  0.389685 -0.070361  0.226413  0.011184 -0.218933 -0.453032  0.584852   \n",
       "26878 -0.166137 -0.135977  0.175625  0.177462 -0.134225 -0.336339 -0.011873   \n",
       "11913 -0.161652 -0.316417  0.087562 -0.180851 -0.263479 -0.251145  0.140881   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "8094  -0.009050 -0.120176 -0.218051 -0.091481 -0.084636 -0.249447  0.164419   \n",
       "18064 -0.268845 -0.285695  0.190564 -0.009600 -0.218369 -0.083192  0.098382   \n",
       "17745  0.209622 -0.083331  0.235984  0.099007 -0.574764 -0.488376  0.100918   \n",
       "62218 -0.404304  0.309166  0.182504 -0.065580 -0.822769 -0.025005  0.732324   \n",
       "2945  -0.435416  0.463265 -0.253529 -0.357788 -0.255868  0.528730  0.770660   \n",
       "\n",
       "              7         8         9  ...       761       762       763  \\\n",
       "40873  0.649390  0.190963 -0.307655  ... -0.607841  0.322955  0.457741   \n",
       "832    0.589370 -0.150682 -0.450952  ... -0.354488  0.312999  0.259520   \n",
       "58367  0.535753 -0.016475 -0.470529  ... -0.505246  0.328158 -0.015673   \n",
       "26878  0.453432 -0.134633 -0.255964  ... -0.554123  0.428766  0.516216   \n",
       "11913  0.424626 -0.035675 -0.417812  ... -0.716426  0.061558  0.553769   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "8094   0.769991 -0.129390 -0.380851  ... -0.254722  0.109970  0.102325   \n",
       "18064  0.317847  0.057382 -0.158775  ... -0.433835  0.000949  0.106776   \n",
       "17745  0.543892 -0.268854 -0.158150  ...  0.103803  0.262976  0.063059   \n",
       "62218 -0.050806 -0.079255 -0.318297  ... -0.295160  0.584818 -0.064049   \n",
       "2945   0.181389  0.393911 -0.556885  ... -0.503047 -0.008470 -0.328027   \n",
       "\n",
       "            764       765       766       767  retweet   time  change_1_direct  \n",
       "40873 -0.102821 -0.443432  0.124357  0.630489     35.0  30493              1.0  \n",
       "832   -0.103768 -0.588483  0.249900  0.225558     21.0  67411              1.0  \n",
       "58367  0.022542 -0.277971  0.256051  0.558487      2.0  63557              1.0  \n",
       "26878 -0.469654 -0.421126  0.073560  0.534384      2.0  46775              1.0  \n",
       "11913 -0.220546 -0.231607 -0.058111  0.782034      7.0  82973              0.0  \n",
       "...         ...       ...       ...       ...      ...    ...              ...  \n",
       "8094  -0.203718 -0.189995  0.076426  0.542887      3.0  54504              1.0  \n",
       "18064 -0.236143 -0.265077  0.033676  0.580178      2.0  60654              0.0  \n",
       "17745 -0.095611 -0.310393  0.297672  0.371484      3.0  71564              1.0  \n",
       "62218 -0.151786 -0.574533  0.430951  0.411983     57.0  38660              1.0  \n",
       "2945  -0.450504 -0.517881  0.559338  0.039356     11.0  58236              1.0  \n",
       "\n",
       "[100000 rows x 771 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#shaffle\n",
    "raw_data = raw_data.sample(frac=1)\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56bef17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#data.corr()[target].sort_values()\n",
    "#train_size = 400000\n",
    "train_size = 80000\n",
    "data = raw_data.iloc[:train_size,:]\n",
    "test = raw_data.iloc[train_size:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fee1a4ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 704 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.1540783 , -0.20139408,  0.02656418, ..., -0.44343206,\n",
       "         0.12435672,  0.63048863],\n",
       "       [ 0.1108293 ,  0.08769724,  0.20337234, ..., -0.58848256,\n",
       "         0.24989972,  0.22555758],\n",
       "       [ 0.38968456, -0.07036075,  0.2264132 , ..., -0.27797145,\n",
       "         0.25605115,  0.55848706],\n",
       "       ...,\n",
       "       [ 0.32227254,  0.07305242,  0.35339764, ..., -0.44655225,\n",
       "         0.21078174,  0.821819  ],\n",
       "       [-0.2651025 , -0.12942639, -0.05632295, ..., -0.22416812,\n",
       "         0.18068723,  0.5076914 ],\n",
       "       [-0.00671956,  0.14567634,  0.36557785, ..., -0.461772  ,\n",
       "         0.50019807,  0.48612818]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#cols_num = 771\n",
    "cols_num = 768\n",
    "x_train = np.array(data.iloc[:,:cols_num])\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63baacf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15888788, -0.00390368, -0.10173465, ..., -0.37399247,\n",
       "         0.19761313,  0.43059814],\n",
       "       [-0.11225191,  0.02365246, -0.2013041 , ..., -0.37025604,\n",
       "         0.41310805,  0.6116906 ],\n",
       "       [-0.6269896 , -0.38341638,  0.09743221, ..., -0.6797356 ,\n",
       "         0.31627098,  0.5092034 ],\n",
       "       ...,\n",
       "       [ 0.20962176, -0.08333102,  0.23598449, ..., -0.31039286,\n",
       "         0.29767215,  0.37148395],\n",
       "       [-0.40430364,  0.30916557,  0.18250442, ..., -0.57453334,\n",
       "         0.4309507 ,  0.41198274],\n",
       "       [-0.4354161 ,  0.46326542, -0.25352922, ..., -0.51788056,\n",
       "         0.55933785,  0.03935561]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.array(test.iloc[:,:cols_num])\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23f80cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'change_1_direct'\n",
    "#data[target].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "844938c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    48254\n",
       "0    31746\n",
       "Name: change_1_direct, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = data[target].astype(int)\n",
    "#y_train = data[target].apply(lambda x: -1 if x < 1 else 1)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5b1e98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12092\n",
       "0     7908\n",
       "Name: change_1_direct, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = test[target].astype(int)\n",
    "#y_test = test[target].apply(lambda x: -1 if x < 1 else 1)\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8d02dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.26000126000126, 1: 0.8289468230613006}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "d_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "197ea21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b94a1c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7e15bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "#l2=0.05\n",
    "lr=0.02\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# activity_regularizer=regularizers.l2(l2), \n",
    "model.add(layers.Dense(400, input_shape=(cols_num,), kernel_initializer=\"he_uniform\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(400, kernel_initializer=\"he_uniform\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "rmsprop = optimizers.RMSprop(learning_rate=lr, rho=0.9)\n",
    "adam = optimizers.Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999, amsgrad=True)\n",
    "adamax = optimizers.Adamax(learning_rate=lr, beta_1=0.9, beta_2=0.99)\n",
    "nadam = optimizers.Nadam(learning_rate=lr, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "print(model_num)\n",
    "model_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62e97aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "weights_file = f'{folder}/weights_pr4_{model_num}.h5'\n",
    "save_weights = ModelCheckpoint(weights_file, monitor='val_binary_accuracy', mode='max', save_best_only=True)\n",
    "tensorboard_cbk = TensorBoard(log_dir=f'{folder}/logs')\n",
    "reduce = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=0.000001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5878ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = f'{folder}/model_pr4_{model_num}.json'\n",
    "model_json = model.to_json()\n",
    "\n",
    "with open(json_file, 'w') as file:\n",
    "    file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e190e84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "10/10 [==============================] - 12s 1s/step - loss: 1.2844 - binary_accuracy: 0.5308 - val_loss: 3.9809 - val_binary_accuracy: 0.5227\n",
      "Epoch 2/25\n",
      "10/10 [==============================] - 5s 529ms/step - loss: 0.7315 - binary_accuracy: 0.5884 - val_loss: 2.1681 - val_binary_accuracy: 0.5668\n",
      "Epoch 3/25\n",
      "10/10 [==============================] - 6s 570ms/step - loss: 0.6984 - binary_accuracy: 0.5963 - val_loss: 0.8501 - val_binary_accuracy: 0.6285\n",
      "Epoch 4/25\n",
      "10/10 [==============================] - 6s 655ms/step - loss: 0.6766 - binary_accuracy: 0.6196 - val_loss: 0.8894 - val_binary_accuracy: 0.6086\n",
      "Epoch 5/25\n",
      "10/10 [==============================] - 6s 587ms/step - loss: 0.6693 - binary_accuracy: 0.6276 - val_loss: 0.7611 - val_binary_accuracy: 0.6244\n",
      "Epoch 6/25\n",
      "10/10 [==============================] - 6s 588ms/step - loss: 0.6693 - binary_accuracy: 0.6263 - val_loss: 0.7370 - val_binary_accuracy: 0.6291\n",
      "Epoch 7/25\n",
      "10/10 [==============================] - 6s 590ms/step - loss: 0.6640 - binary_accuracy: 0.6360 - val_loss: 0.7207 - val_binary_accuracy: 0.6312\n",
      "Epoch 8/25\n",
      "10/10 [==============================] - 7s 697ms/step - loss: 0.6666 - binary_accuracy: 0.6329 - val_loss: 0.7109 - val_binary_accuracy: 0.6335\n",
      "Epoch 9/25\n",
      "10/10 [==============================] - 6s 583ms/step - loss: 0.6629 - binary_accuracy: 0.6393 - val_loss: 0.6883 - val_binary_accuracy: 0.6400\n",
      "Epoch 10/25\n",
      "10/10 [==============================] - 6s 642ms/step - loss: 0.6647 - binary_accuracy: 0.6352 - val_loss: 0.6792 - val_binary_accuracy: 0.6415\n",
      "Epoch 11/25\n",
      "10/10 [==============================] - 6s 587ms/step - loss: 0.6642 - binary_accuracy: 0.6379 - val_loss: 0.6837 - val_binary_accuracy: 0.6419\n",
      "Epoch 12/25\n",
      "10/10 [==============================] - 7s 675ms/step - loss: 0.6636 - binary_accuracy: 0.6371 - val_loss: 0.6724 - val_binary_accuracy: 0.6433\n",
      "Epoch 13/25\n",
      "10/10 [==============================] - 6s 616ms/step - loss: 0.6622 - binary_accuracy: 0.6375 - val_loss: 0.6667 - val_binary_accuracy: 0.6454\n",
      "Epoch 14/25\n",
      "10/10 [==============================] - 7s 673ms/step - loss: 0.6655 - binary_accuracy: 0.6322 - val_loss: 0.6645 - val_binary_accuracy: 0.6455\n",
      "Epoch 15/25\n",
      "10/10 [==============================] - 7s 725ms/step - loss: 0.6629 - binary_accuracy: 0.6397 - val_loss: 0.6621 - val_binary_accuracy: 0.6461\n",
      "Epoch 16/25\n",
      "10/10 [==============================] - 6s 647ms/step - loss: 0.6610 - binary_accuracy: 0.6408 - val_loss: 0.6589 - val_binary_accuracy: 0.6470\n",
      "Epoch 17/25\n",
      "10/10 [==============================] - 7s 719ms/step - loss: 0.6628 - binary_accuracy: 0.6405 - val_loss: 0.6596 - val_binary_accuracy: 0.6482\n",
      "Epoch 18/25\n",
      "10/10 [==============================] - 7s 710ms/step - loss: 0.6597 - binary_accuracy: 0.6411 - val_loss: 0.6727 - val_binary_accuracy: 0.6463\n",
      "Epoch 19/25\n",
      "10/10 [==============================] - 7s 672ms/step - loss: 0.6624 - binary_accuracy: 0.6291 - val_loss: 0.6652 - val_binary_accuracy: 0.6474\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.009999999776482582.\n",
      "Epoch 20/25\n",
      "10/10 [==============================] - 7s 765ms/step - loss: 0.6591 - binary_accuracy: 0.6358 - val_loss: 0.6594 - val_binary_accuracy: 0.6473\n",
      "Epoch 21/25\n",
      "10/10 [==============================] - 6s 672ms/step - loss: 0.6579 - binary_accuracy: 0.6408 - val_loss: 0.6535 - val_binary_accuracy: 0.6487\n",
      "Epoch 22/25\n",
      "10/10 [==============================] - 6s 639ms/step - loss: 0.6570 - binary_accuracy: 0.6413 - val_loss: 0.6558 - val_binary_accuracy: 0.6486\n",
      "Epoch 23/25\n",
      "10/10 [==============================] - 7s 711ms/step - loss: 0.6577 - binary_accuracy: 0.6399 - val_loss: 0.6605 - val_binary_accuracy: 0.6475\n",
      "Epoch 24/25\n",
      "10/10 [==============================] - 6s 645ms/step - loss: 0.6556 - binary_accuracy: 0.6392 - val_loss: 0.6578 - val_binary_accuracy: 0.6486\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 25/25\n",
      "10/10 [==============================] - 7s 664ms/step - loss: 0.6574 - binary_accuracy: 0.6387 - val_loss: 0.6581 - val_binary_accuracy: 0.6472\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, class_weight=d_class_weights, epochs=25, batch_size=4000, validation_split=0.5, callbacks=[save_weights, tensorboard_cbk, reduce])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd7e2489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x19884d9f280>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "start = 5\n",
    "loss_values = history.history['loss'][start:]\n",
    "val_loss_values = history.history['val_loss'][start:]\n",
    "epochs = range(start, len(loss_values) + start)\n",
    "plt.plot(epochs, loss_values, 'g', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec2b60b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "acc_values = history.history['binary_accuracy']\n",
    "val_acc_values = history.history['val_binary_accuracy']\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "plt.plot(epochs, acc_values, 'g', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "plt.title('Training and validation binary_accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('binary_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb811f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 3s 4ms/step - loss: 0.6581 - binary_accuracy: 0.6468\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e5a0a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier score: 0.605 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf_dummy = DummyClassifier()\n",
    "\n",
    "scores = cross_val_score(clf_dummy, x_test, y_test)\n",
    "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1735d8fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3760522 , 0.5893599 , 0.2978202 , ..., 0.36077154, 1.        ,\n",
       "        0.57056653]], dtype=float32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "predictions.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "315ad4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    35576\n",
       "0    14424\n",
       "Name: change_1_direct, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "predictions_df = pd.DataFrame()\n",
    "predictions_df[target] = [1 if val > threshold else 0 for val in predictions]\n",
    "predictions_df[target].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1999638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a76b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(y_test, predictions_df[target], average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c488f5e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11841  2583]\n",
      " [14381 21195]]\n",
      "0.66072\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(predictions_df[target], y_test))\n",
    "print(confusion_matrix(predictions_df[target], y_test))\n",
    "print(accuracy_score(predictions_df[target], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be852984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f1403d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\git\\project1\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'C': 0.0001}\n",
      "best scrores:  0.8089999999999999\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parameters = {'C': np.linspace(0.0001, 100, 20)}\n",
    "grid_search = GridSearchCV(LogisticRegression(solver=\"saga\"), parameters)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "print('best parameters: ', grid_search.best_params_)\n",
    "print('best scrores: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2c12a5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 832 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0001, solver='saga')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf = LogisticRegression(solver=\"warn\", C=1)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a63ffaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.783"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1b8a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data={'score': model['lr'].coef_[0]},\n",
    "                      index=column_names).sort_values(by='score')\n",
    "                                         .plot(kind='barh', grid=True,\n",
    "                                               figsize=(6,6), legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "10e6f387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "94947fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=1000)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier(n_estimators = 1000)\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9544931d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.787"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5e0bf043",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6c50b96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[783 213]\n",
      " [  0   4]]\n",
      "0.787\n"
     ]
    }
   ],
   "source": [
    "#print(roc_auc_score(predictions_df[target], y_test))\n",
    "print(confusion_matrix(rf_pred, y_test))\n",
    "print(accuracy_score(rf_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a992e4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data={'score': model['rf'].feature_importances_}, \n",
    "                      index=column_names).sort_values(by='score')\n",
    "                                         .plot(kind='barh', grid=True,\n",
    "                                               figsize=(6,6), legend=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

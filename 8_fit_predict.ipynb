{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c53c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "folder = 'd:/git/project1/generated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b783b4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>direct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.571585</td>\n",
       "      <td>0.140949</td>\n",
       "      <td>0.060760</td>\n",
       "      <td>0.153261</td>\n",
       "      <td>-0.145271</td>\n",
       "      <td>0.115880</td>\n",
       "      <td>0.497591</td>\n",
       "      <td>0.415114</td>\n",
       "      <td>-0.482140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493163</td>\n",
       "      <td>0.115500</td>\n",
       "      <td>0.248566</td>\n",
       "      <td>-0.254553</td>\n",
       "      <td>0.296603</td>\n",
       "      <td>-0.572895</td>\n",
       "      <td>-0.096047</td>\n",
       "      <td>0.210568</td>\n",
       "      <td>1553817600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.379941</td>\n",
       "      <td>-0.027598</td>\n",
       "      <td>-0.004053</td>\n",
       "      <td>-0.293699</td>\n",
       "      <td>-0.261320</td>\n",
       "      <td>-0.360896</td>\n",
       "      <td>0.477414</td>\n",
       "      <td>0.384128</td>\n",
       "      <td>-0.080506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289536</td>\n",
       "      <td>-0.000280</td>\n",
       "      <td>0.316195</td>\n",
       "      <td>-0.265717</td>\n",
       "      <td>-0.172322</td>\n",
       "      <td>-0.388621</td>\n",
       "      <td>0.272517</td>\n",
       "      <td>0.179656</td>\n",
       "      <td>1594857600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.473415</td>\n",
       "      <td>-0.110131</td>\n",
       "      <td>0.158560</td>\n",
       "      <td>-0.018178</td>\n",
       "      <td>-0.503009</td>\n",
       "      <td>0.266457</td>\n",
       "      <td>0.501562</td>\n",
       "      <td>0.132371</td>\n",
       "      <td>-0.278618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470979</td>\n",
       "      <td>-0.206761</td>\n",
       "      <td>-0.019523</td>\n",
       "      <td>-0.423772</td>\n",
       "      <td>-0.214560</td>\n",
       "      <td>-0.261824</td>\n",
       "      <td>0.538293</td>\n",
       "      <td>0.213355</td>\n",
       "      <td>1551657600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.557469</td>\n",
       "      <td>-0.117192</td>\n",
       "      <td>-0.171127</td>\n",
       "      <td>-0.016516</td>\n",
       "      <td>-0.639803</td>\n",
       "      <td>-0.098061</td>\n",
       "      <td>0.677578</td>\n",
       "      <td>0.374796</td>\n",
       "      <td>-0.213820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149891</td>\n",
       "      <td>-0.405337</td>\n",
       "      <td>0.313279</td>\n",
       "      <td>-0.265779</td>\n",
       "      <td>0.195671</td>\n",
       "      <td>-0.648685</td>\n",
       "      <td>0.202946</td>\n",
       "      <td>0.170861</td>\n",
       "      <td>1570838400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.020235</td>\n",
       "      <td>-0.063642</td>\n",
       "      <td>-0.252436</td>\n",
       "      <td>-0.144558</td>\n",
       "      <td>-0.467133</td>\n",
       "      <td>0.015928</td>\n",
       "      <td>0.411918</td>\n",
       "      <td>0.571481</td>\n",
       "      <td>-0.618786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301235</td>\n",
       "      <td>-0.233004</td>\n",
       "      <td>0.373178</td>\n",
       "      <td>-0.012555</td>\n",
       "      <td>-0.001489</td>\n",
       "      <td>-1.000661</td>\n",
       "      <td>-0.315609</td>\n",
       "      <td>0.589265</td>\n",
       "      <td>1571011200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>994</td>\n",
       "      <td>-0.313278</td>\n",
       "      <td>0.380004</td>\n",
       "      <td>-0.575349</td>\n",
       "      <td>0.124349</td>\n",
       "      <td>-0.489599</td>\n",
       "      <td>-0.088549</td>\n",
       "      <td>0.300775</td>\n",
       "      <td>0.429332</td>\n",
       "      <td>-0.601158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458268</td>\n",
       "      <td>-0.193398</td>\n",
       "      <td>0.357428</td>\n",
       "      <td>-0.214028</td>\n",
       "      <td>-0.200165</td>\n",
       "      <td>-0.667590</td>\n",
       "      <td>0.270811</td>\n",
       "      <td>-0.420819</td>\n",
       "      <td>1596585600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>995</td>\n",
       "      <td>-0.635597</td>\n",
       "      <td>-0.319952</td>\n",
       "      <td>-0.078306</td>\n",
       "      <td>-0.319213</td>\n",
       "      <td>0.315180</td>\n",
       "      <td>0.763312</td>\n",
       "      <td>0.633995</td>\n",
       "      <td>0.686098</td>\n",
       "      <td>-0.802083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089779</td>\n",
       "      <td>-0.202869</td>\n",
       "      <td>0.800985</td>\n",
       "      <td>0.175762</td>\n",
       "      <td>-0.480878</td>\n",
       "      <td>-0.343280</td>\n",
       "      <td>0.392773</td>\n",
       "      <td>-0.520307</td>\n",
       "      <td>1578700800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>996</td>\n",
       "      <td>-0.289571</td>\n",
       "      <td>0.020761</td>\n",
       "      <td>-0.468140</td>\n",
       "      <td>0.178034</td>\n",
       "      <td>0.021940</td>\n",
       "      <td>0.074094</td>\n",
       "      <td>-0.066568</td>\n",
       "      <td>0.555133</td>\n",
       "      <td>-0.139029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269067</td>\n",
       "      <td>-0.204563</td>\n",
       "      <td>-0.077712</td>\n",
       "      <td>-0.024960</td>\n",
       "      <td>-0.503745</td>\n",
       "      <td>-0.245689</td>\n",
       "      <td>0.243844</td>\n",
       "      <td>0.183795</td>\n",
       "      <td>1589760000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>997</td>\n",
       "      <td>-0.607803</td>\n",
       "      <td>-0.621990</td>\n",
       "      <td>-0.086619</td>\n",
       "      <td>-0.366173</td>\n",
       "      <td>-0.142485</td>\n",
       "      <td>-0.300152</td>\n",
       "      <td>0.590557</td>\n",
       "      <td>0.913629</td>\n",
       "      <td>-0.562190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114494</td>\n",
       "      <td>0.080221</td>\n",
       "      <td>0.056756</td>\n",
       "      <td>0.184996</td>\n",
       "      <td>-0.547618</td>\n",
       "      <td>-0.351712</td>\n",
       "      <td>0.459963</td>\n",
       "      <td>0.158522</td>\n",
       "      <td>1589760000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>998</td>\n",
       "      <td>-0.373565</td>\n",
       "      <td>0.205868</td>\n",
       "      <td>0.073435</td>\n",
       "      <td>0.050534</td>\n",
       "      <td>-0.301561</td>\n",
       "      <td>0.129777</td>\n",
       "      <td>0.242060</td>\n",
       "      <td>-0.079856</td>\n",
       "      <td>0.059284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094643</td>\n",
       "      <td>0.153705</td>\n",
       "      <td>0.105666</td>\n",
       "      <td>-0.158565</td>\n",
       "      <td>-0.058671</td>\n",
       "      <td>-0.613318</td>\n",
       "      <td>0.341379</td>\n",
       "      <td>-0.045696</td>\n",
       "      <td>1587772800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9990 rows × 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0         0         1         2         3         4         5  \\\n",
       "0              0 -0.571585  0.140949  0.060760  0.153261 -0.145271  0.115880   \n",
       "1              1 -0.379941 -0.027598 -0.004053 -0.293699 -0.261320 -0.360896   \n",
       "2              2 -0.473415 -0.110131  0.158560 -0.018178 -0.503009  0.266457   \n",
       "3              3 -0.557469 -0.117192 -0.171127 -0.016516 -0.639803 -0.098061   \n",
       "4              4 -0.020235 -0.063642 -0.252436 -0.144558 -0.467133  0.015928   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "9985         994 -0.313278  0.380004 -0.575349  0.124349 -0.489599 -0.088549   \n",
       "9986         995 -0.635597 -0.319952 -0.078306 -0.319213  0.315180  0.763312   \n",
       "9987         996 -0.289571  0.020761 -0.468140  0.178034  0.021940  0.074094   \n",
       "9988         997 -0.607803 -0.621990 -0.086619 -0.366173 -0.142485 -0.300152   \n",
       "9989         998 -0.373565  0.205868  0.073435  0.050534 -0.301561  0.129777   \n",
       "\n",
       "             6         7         8  ...       760       761       762  \\\n",
       "0     0.497591  0.415114 -0.482140  ...  0.493163  0.115500  0.248566   \n",
       "1     0.477414  0.384128 -0.080506  ...  0.289536 -0.000280  0.316195   \n",
       "2     0.501562  0.132371 -0.278618  ...  0.470979 -0.206761 -0.019523   \n",
       "3     0.677578  0.374796 -0.213820  ...  0.149891 -0.405337  0.313279   \n",
       "4     0.411918  0.571481 -0.618786  ...  0.301235 -0.233004  0.373178   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "9985  0.300775  0.429332 -0.601158  ...  0.458268 -0.193398  0.357428   \n",
       "9986  0.633995  0.686098 -0.802083  ...  0.089779 -0.202869  0.800985   \n",
       "9987 -0.066568  0.555133 -0.139029  ...  0.269067 -0.204563 -0.077712   \n",
       "9988  0.590557  0.913629 -0.562190  ...  0.114494  0.080221  0.056756   \n",
       "9989  0.242060 -0.079856  0.059284  ...  0.094643  0.153705  0.105666   \n",
       "\n",
       "           763       764       765       766       767   timestamp  direct  \n",
       "0    -0.254553  0.296603 -0.572895 -0.096047  0.210568  1553817600       1  \n",
       "1    -0.265717 -0.172322 -0.388621  0.272517  0.179656  1594857600       0  \n",
       "2    -0.423772 -0.214560 -0.261824  0.538293  0.213355  1551657600       1  \n",
       "3    -0.265779  0.195671 -0.648685  0.202946  0.170861  1570838400       0  \n",
       "4    -0.012555 -0.001489 -1.000661 -0.315609  0.589265  1571011200       0  \n",
       "...        ...       ...       ...       ...       ...         ...     ...  \n",
       "9985 -0.214028 -0.200165 -0.667590  0.270811 -0.420819  1596585600       1  \n",
       "9986  0.175762 -0.480878 -0.343280  0.392773 -0.520307  1578700800       1  \n",
       "9987 -0.024960 -0.503745 -0.245689  0.243844  0.183795  1589760000       1  \n",
       "9988  0.184996 -0.547618 -0.351712  0.459963  0.158522  1589760000       1  \n",
       "9989 -0.158565 -0.058671 -0.613318  0.341379 -0.045696  1587772800       1  \n",
       "\n",
       "[9990 rows x 771 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_csv(f'{folder}/set_393.csv')\n",
    "data = pd.read_csv(f'{folder}/cls_direct30_9.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23f80cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6377\n",
       "0    3613\n",
       "Name: direct, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.direct.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56bef17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "366         -0.031952\n",
       "286         -0.027817\n",
       "690         -0.027267\n",
       "216         -0.026184\n",
       "538         -0.023844\n",
       "               ...   \n",
       "463          0.025095\n",
       "437          0.025594\n",
       "642          0.028509\n",
       "timestamp    0.039128\n",
       "direct       1.000000\n",
       "Name: direct, Length: 771, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data.corr()['direct'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fee1a4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.4094940e-01,  6.0760103e-02,  1.5326059e-01, ...,\n",
       "        -9.6046895e-02,  2.1056804e-01,  1.5538176e+09],\n",
       "       [-2.7598329e-02, -4.0533207e-03, -2.9369882e-01, ...,\n",
       "         2.7251676e-01,  1.7965640e-01,  1.5948576e+09],\n",
       "       [-1.1013101e-01,  1.5856001e-01, -1.8177794e-02, ...,\n",
       "         5.3829290e-01,  2.1335493e-01,  1.5516576e+09],\n",
       "       ...,\n",
       "       [ 2.0760603e-02, -4.6814045e-01,  1.7803444e-01, ...,\n",
       "         2.4384356e-01,  1.8379502e-01,  1.5897600e+09],\n",
       "       [-6.2198970e-01, -8.6618740e-02, -3.6617282e-01, ...,\n",
       "         4.5996305e-01,  1.5852162e-01,  1.5897600e+09],\n",
       "       [ 2.0586786e-01,  7.3434606e-02,  5.0533630e-02, ...,\n",
       "         3.4137884e-01, -4.5696065e-02,  1.5877728e+09]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.array(data.iloc[:,2:770])\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "844938c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9985    1\n",
       "9986    1\n",
       "9987    1\n",
       "9988    1\n",
       "9989    1\n",
       "Name: direct, Length: 9990, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = data['direct']\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "197ea21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62e97aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "weights_file = f'{folder}/weights3.h5'\n",
    "callback = ModelCheckpoint(weights_file, monitor='val_binary_accuracy', mode='max', save_best_only=True)\n",
    "tensorboard_cbk = TensorBoard(log_dir=f'{folder}/logs')\n",
    "reduce = ReduceLROnPlateau(monitor=\"val_loss\", patience=5, min_lr=0.000001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b7e15bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "# activity_regularizer=regularizers.l2(0.05), \n",
    "model.add(layers.Dense(768, input_shape=(768,), kernel_initializer=\"he_uniform\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(384, kernel_initializer=\"he_uniform\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(192, kernel_initializer=\"he_uniform\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(96, kernel_initializer=\"he_uniform\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(48, kernel_initializer=\"he_uniform\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(24, kernel_initializer=\"he_uniform\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(12, kernel_initializer=\"he_uniform\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(8, kernel_initializer=\"he_uniform\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(4, kernel_initializer=\"he_uniform\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(2, kernel_initializer=\"he_uniform\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "model.add(layers.Dense(1, activation='softmax'))\n",
    "\n",
    "#model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f5878ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = f'{folder}/model12.json'\n",
    "model_json = model.to_json()\n",
    "\n",
    "with open(json_file, 'w') as file:\n",
    "    file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2e190e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "4/4 [==============================] - 12s 2s/step - loss: 0.7292 - binary_accuracy: 0.6433 - val_loss: 0.6926 - val_binary_accuracy: 0.6400\n",
      "Epoch 2/120\n",
      "4/4 [==============================] - 2s 451ms/step - loss: 0.7245 - binary_accuracy: 0.6396 - val_loss: 0.6920 - val_binary_accuracy: 0.6400\n",
      "Epoch 3/120\n",
      "4/4 [==============================] - 2s 496ms/step - loss: 0.7261 - binary_accuracy: 0.6354 - val_loss: 0.6915 - val_binary_accuracy: 0.6400\n",
      "Epoch 4/120\n",
      "4/4 [==============================] - 2s 426ms/step - loss: 0.7109 - binary_accuracy: 0.6351 - val_loss: 31.1053 - val_binary_accuracy: 0.6400\n",
      "Epoch 5/120\n",
      "4/4 [==============================] - 2s 434ms/step - loss: 0.7126 - binary_accuracy: 0.6368 - val_loss: 53.5863 - val_binary_accuracy: 0.6400\n",
      "Epoch 6/120\n",
      "4/4 [==============================] - 2s 513ms/step - loss: 0.7138 - binary_accuracy: 0.6403 - val_loss: 74.5936 - val_binary_accuracy: 0.6400\n",
      "Epoch 7/120\n",
      "4/4 [==============================] - 2s 441ms/step - loss: 0.7141 - binary_accuracy: 0.6380 - val_loss: 87.6546 - val_binary_accuracy: 0.6400\n",
      "Epoch 8/120\n",
      "4/4 [==============================] - 2s 482ms/step - loss: 0.7049 - binary_accuracy: 0.6362 - val_loss: 98.1854 - val_binary_accuracy: 0.6400\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 9/120\n",
      "4/4 [==============================] - 2s 432ms/step - loss: 0.7017 - binary_accuracy: 0.6379 - val_loss: 82.7796 - val_binary_accuracy: 0.6400\n",
      "Epoch 10/120\n",
      "4/4 [==============================] - 2s 466ms/step - loss: 0.7041 - binary_accuracy: 0.6350 - val_loss: 70.6764 - val_binary_accuracy: 0.6400\n",
      "Epoch 11/120\n",
      "4/4 [==============================] - 2s 431ms/step - loss: 0.7089 - binary_accuracy: 0.6423 - val_loss: 60.8736 - val_binary_accuracy: 0.6400\n",
      "Epoch 12/120\n",
      "4/4 [==============================] - 2s 470ms/step - loss: 0.7010 - binary_accuracy: 0.6385 - val_loss: 53.1375 - val_binary_accuracy: 0.6400\n",
      "Epoch 13/120\n",
      "4/4 [==============================] - 2s 427ms/step - loss: 0.7049 - binary_accuracy: 0.6357 - val_loss: 46.3604 - val_binary_accuracy: 0.6400\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 14/120\n",
      "4/4 [==============================] - 2s 431ms/step - loss: 0.7048 - binary_accuracy: 0.6362 - val_loss: 40.4256 - val_binary_accuracy: 0.6400\n",
      "Epoch 15/120\n",
      "4/4 [==============================] - 2s 454ms/step - loss: 0.6992 - binary_accuracy: 0.6381 - val_loss: 35.3741 - val_binary_accuracy: 0.6400\n",
      "Epoch 16/120\n",
      "4/4 [==============================] - 2s 432ms/step - loss: 0.7058 - binary_accuracy: 0.6335 - val_loss: 31.2116 - val_binary_accuracy: 0.6400\n",
      "Epoch 17/120\n",
      "4/4 [==============================] - 2s 468ms/step - loss: 0.7026 - binary_accuracy: 0.6327 - val_loss: 27.6852 - val_binary_accuracy: 0.6400\n",
      "Epoch 18/120\n",
      "4/4 [==============================] - 2s 429ms/step - loss: 0.7047 - binary_accuracy: 0.6332 - val_loss: 24.7371 - val_binary_accuracy: 0.6400\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 19/120\n",
      "4/4 [==============================] - 2s 423ms/step - loss: 0.7068 - binary_accuracy: 0.6399 - val_loss: 21.9970 - val_binary_accuracy: 0.6400\n",
      "Epoch 20/120\n",
      "4/4 [==============================] - 2s 441ms/step - loss: 0.7064 - binary_accuracy: 0.6379 - val_loss: 19.9125 - val_binary_accuracy: 0.6400\n",
      "Epoch 21/120\n",
      "4/4 [==============================] - 2s 427ms/step - loss: 0.7060 - binary_accuracy: 0.6365 - val_loss: 18.0529 - val_binary_accuracy: 0.6400\n",
      "Epoch 22/120\n",
      "4/4 [==============================] - 2s 439ms/step - loss: 0.7100 - binary_accuracy: 0.6368 - val_loss: 16.3733 - val_binary_accuracy: 0.6400\n",
      "Epoch 23/120\n",
      "4/4 [==============================] - 2s 447ms/step - loss: 0.7081 - binary_accuracy: 0.6350 - val_loss: 14.8536 - val_binary_accuracy: 0.6400\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 24/120\n",
      "4/4 [==============================] - 2s 431ms/step - loss: 0.7079 - binary_accuracy: 0.6420 - val_loss: 13.5446 - val_binary_accuracy: 0.6400\n",
      "Epoch 25/120\n",
      "4/4 [==============================] - 2s 439ms/step - loss: 0.7021 - binary_accuracy: 0.6338 - val_loss: 12.3837 - val_binary_accuracy: 0.6400\n",
      "Epoch 26/120\n",
      "4/4 [==============================] - 2s 472ms/step - loss: 0.7049 - binary_accuracy: 0.6352 - val_loss: 11.3461 - val_binary_accuracy: 0.6400\n",
      "Epoch 27/120\n",
      "4/4 [==============================] - 2s 437ms/step - loss: 0.7009 - binary_accuracy: 0.6374 - val_loss: 10.4545 - val_binary_accuracy: 0.6400\n",
      "Epoch 28/120\n",
      "4/4 [==============================] - 2s 436ms/step - loss: 0.6965 - binary_accuracy: 0.6399 - val_loss: 9.5781 - val_binary_accuracy: 0.6400\n",
      "Epoch 29/120\n",
      "4/4 [==============================] - 2s 428ms/step - loss: 0.7076 - binary_accuracy: 0.6401 - val_loss: 8.7776 - val_binary_accuracy: 0.6400\n",
      "Epoch 30/120\n",
      "4/4 [==============================] - 2s 469ms/step - loss: 0.7062 - binary_accuracy: 0.6345 - val_loss: 8.0861 - val_binary_accuracy: 0.6400\n",
      "Epoch 31/120\n",
      "4/4 [==============================] - 2s 526ms/step - loss: 0.7051 - binary_accuracy: 0.6401 - val_loss: 7.4883 - val_binary_accuracy: 0.6400\n",
      "Epoch 32/120\n",
      "4/4 [==============================] - 2s 464ms/step - loss: 0.7041 - binary_accuracy: 0.6359 - val_loss: 6.8918 - val_binary_accuracy: 0.6400\n",
      "Epoch 33/120\n",
      "4/4 [==============================] - 2s 460ms/step - loss: 0.7058 - binary_accuracy: 0.6420 - val_loss: 6.3523 - val_binary_accuracy: 0.6400\n",
      "Epoch 34/120\n",
      "4/4 [==============================] - 2s 483ms/step - loss: 0.7024 - binary_accuracy: 0.6390 - val_loss: 5.9106 - val_binary_accuracy: 0.6400\n",
      "Epoch 35/120\n",
      "4/4 [==============================] - 2s 477ms/step - loss: 0.7073 - binary_accuracy: 0.6415 - val_loss: 5.4940 - val_binary_accuracy: 0.6400\n",
      "Epoch 36/120\n",
      "4/4 [==============================] - 2s 433ms/step - loss: 0.7097 - binary_accuracy: 0.6417 - val_loss: 5.1083 - val_binary_accuracy: 0.6400\n",
      "Epoch 37/120\n",
      "4/4 [==============================] - 2s 420ms/step - loss: 0.7077 - binary_accuracy: 0.6415 - val_loss: 4.7784 - val_binary_accuracy: 0.6400\n",
      "Epoch 38/120\n",
      "4/4 [==============================] - 2s 447ms/step - loss: 0.7099 - binary_accuracy: 0.6354 - val_loss: 4.4862 - val_binary_accuracy: 0.6400\n",
      "Epoch 39/120\n",
      "4/4 [==============================] - 2s 433ms/step - loss: 0.7048 - binary_accuracy: 0.6391 - val_loss: 4.1811 - val_binary_accuracy: 0.6400\n",
      "Epoch 40/120\n",
      "4/4 [==============================] - 2s 441ms/step - loss: 0.7097 - binary_accuracy: 0.6372 - val_loss: 3.8955 - val_binary_accuracy: 0.6400\n",
      "Epoch 41/120\n",
      "4/4 [==============================] - 2s 439ms/step - loss: 0.7019 - binary_accuracy: 0.6417 - val_loss: 3.6383 - val_binary_accuracy: 0.6400\n",
      "Epoch 42/120\n",
      "4/4 [==============================] - 2s 433ms/step - loss: 0.7056 - binary_accuracy: 0.6359 - val_loss: 3.4007 - val_binary_accuracy: 0.6400\n",
      "Epoch 43/120\n",
      "4/4 [==============================] - 2s 451ms/step - loss: 0.7095 - binary_accuracy: 0.6334 - val_loss: 3.2099 - val_binary_accuracy: 0.6400\n",
      "Epoch 44/120\n",
      "4/4 [==============================] - 2s 454ms/step - loss: 0.7022 - binary_accuracy: 0.6369 - val_loss: 3.0156 - val_binary_accuracy: 0.6400\n",
      "Epoch 45/120\n",
      "4/4 [==============================] - 2s 429ms/step - loss: 0.7055 - binary_accuracy: 0.6345 - val_loss: 2.8191 - val_binary_accuracy: 0.6400\n",
      "Epoch 46/120\n",
      "4/4 [==============================] - 2s 503ms/step - loss: 0.7054 - binary_accuracy: 0.6343 - val_loss: 2.6528 - val_binary_accuracy: 0.6400\n",
      "Epoch 47/120\n",
      "4/4 [==============================] - 2s 440ms/step - loss: 0.7089 - binary_accuracy: 0.6414 - val_loss: 2.5025 - val_binary_accuracy: 0.6400\n",
      "Epoch 48/120\n",
      "4/4 [==============================] - 2s 561ms/step - loss: 0.7007 - binary_accuracy: 0.6384 - val_loss: 2.3462 - val_binary_accuracy: 0.6400\n",
      "Epoch 49/120\n",
      "4/4 [==============================] - 2s 469ms/step - loss: 0.7018 - binary_accuracy: 0.6364 - val_loss: 2.1989 - val_binary_accuracy: 0.6400\n",
      "Epoch 50/120\n",
      "4/4 [==============================] - 2s 429ms/step - loss: 0.7064 - binary_accuracy: 0.6370 - val_loss: 2.0729 - val_binary_accuracy: 0.6400\n",
      "Epoch 51/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 438ms/step - loss: 0.7075 - binary_accuracy: 0.6329 - val_loss: 1.9506 - val_binary_accuracy: 0.6400\n",
      "Epoch 52/120\n",
      "4/4 [==============================] - 2s 423ms/step - loss: 0.7043 - binary_accuracy: 0.6351 - val_loss: 1.8287 - val_binary_accuracy: 0.6400\n",
      "Epoch 53/120\n",
      "4/4 [==============================] - 2s 418ms/step - loss: 0.7055 - binary_accuracy: 0.6403 - val_loss: 1.7260 - val_binary_accuracy: 0.6400\n",
      "Epoch 54/120\n",
      "4/4 [==============================] - 2s 438ms/step - loss: 0.7056 - binary_accuracy: 0.6330 - val_loss: 1.6249 - val_binary_accuracy: 0.6400\n",
      "Epoch 55/120\n",
      "4/4 [==============================] - 2s 423ms/step - loss: 0.7043 - binary_accuracy: 0.6369 - val_loss: 1.5396 - val_binary_accuracy: 0.6400\n",
      "Epoch 56/120\n",
      "4/4 [==============================] - 2s 437ms/step - loss: 0.7012 - binary_accuracy: 0.6379 - val_loss: 1.4473 - val_binary_accuracy: 0.6400\n",
      "Epoch 57/120\n",
      "4/4 [==============================] - 2s 433ms/step - loss: 0.7064 - binary_accuracy: 0.6412 - val_loss: 1.3713 - val_binary_accuracy: 0.6400\n",
      "Epoch 58/120\n",
      "4/4 [==============================] - 2s 428ms/step - loss: 0.7057 - binary_accuracy: 0.6395 - val_loss: 1.2976 - val_binary_accuracy: 0.6400\n",
      "Epoch 59/120\n",
      "4/4 [==============================] - 2s 428ms/step - loss: 0.7152 - binary_accuracy: 0.6338 - val_loss: 1.2289 - val_binary_accuracy: 0.6400\n",
      "Epoch 60/120\n",
      "4/4 [==============================] - 2s 437ms/step - loss: 0.7049 - binary_accuracy: 0.6399 - val_loss: 1.1724 - val_binary_accuracy: 0.6400\n",
      "Epoch 61/120\n",
      "4/4 [==============================] - 2s 451ms/step - loss: 0.7072 - binary_accuracy: 0.6380 - val_loss: 1.1208 - val_binary_accuracy: 0.6400\n",
      "Epoch 62/120\n",
      "4/4 [==============================] - 2s 466ms/step - loss: 0.7025 - binary_accuracy: 0.6397 - val_loss: 1.0674 - val_binary_accuracy: 0.6400\n",
      "Epoch 63/120\n",
      "4/4 [==============================] - 2s 424ms/step - loss: 0.7076 - binary_accuracy: 0.6417 - val_loss: 1.0148 - val_binary_accuracy: 0.6400\n",
      "Epoch 64/120\n",
      "4/4 [==============================] - 2s 480ms/step - loss: 0.7081 - binary_accuracy: 0.6396 - val_loss: 0.9701 - val_binary_accuracy: 0.6400\n",
      "Epoch 65/120\n",
      "4/4 [==============================] - 2s 549ms/step - loss: 0.7046 - binary_accuracy: 0.6378 - val_loss: 0.9257 - val_binary_accuracy: 0.6400\n",
      "Epoch 66/120\n",
      "4/4 [==============================] - 2s 548ms/step - loss: 0.7132 - binary_accuracy: 0.6400 - val_loss: 0.8912 - val_binary_accuracy: 0.6400\n",
      "Epoch 67/120\n",
      "4/4 [==============================] - 2s 562ms/step - loss: 0.7118 - binary_accuracy: 0.6345 - val_loss: 0.8603 - val_binary_accuracy: 0.6400\n",
      "Epoch 68/120\n",
      "4/4 [==============================] - 2s 489ms/step - loss: 0.7002 - binary_accuracy: 0.6393 - val_loss: 0.8301 - val_binary_accuracy: 0.6400\n",
      "Epoch 69/120\n",
      "4/4 [==============================] - 2s 448ms/step - loss: 0.7050 - binary_accuracy: 0.6362 - val_loss: 0.8070 - val_binary_accuracy: 0.6400\n",
      "Epoch 70/120\n",
      "4/4 [==============================] - 2s 536ms/step - loss: 0.7022 - binary_accuracy: 0.6395 - val_loss: 0.7818 - val_binary_accuracy: 0.6400\n",
      "Epoch 71/120\n",
      "4/4 [==============================] - 2s 441ms/step - loss: 0.7064 - binary_accuracy: 0.6418 - val_loss: 0.7634 - val_binary_accuracy: 0.6400\n",
      "Epoch 72/120\n",
      "4/4 [==============================] - 2s 480ms/step - loss: 0.7071 - binary_accuracy: 0.6336 - val_loss: 0.7459 - val_binary_accuracy: 0.6400\n",
      "Epoch 73/120\n",
      "4/4 [==============================] - 2s 453ms/step - loss: 0.7072 - binary_accuracy: 0.6343 - val_loss: 0.7300 - val_binary_accuracy: 0.6400\n",
      "Epoch 74/120\n",
      "4/4 [==============================] - 2s 429ms/step - loss: 0.6973 - binary_accuracy: 0.6407 - val_loss: 0.7164 - val_binary_accuracy: 0.6400\n",
      "Epoch 75/120\n",
      "4/4 [==============================] - 2s 437ms/step - loss: 0.6994 - binary_accuracy: 0.6424 - val_loss: 0.7035 - val_binary_accuracy: 0.6400\n",
      "Epoch 76/120\n",
      "4/4 [==============================] - 2s 469ms/step - loss: 0.7076 - binary_accuracy: 0.6372 - val_loss: 0.6934 - val_binary_accuracy: 0.6400\n",
      "Epoch 77/120\n",
      "4/4 [==============================] - 2s 458ms/step - loss: 0.7025 - binary_accuracy: 0.6388 - val_loss: 0.6848 - val_binary_accuracy: 0.6400\n",
      "Epoch 78/120\n",
      "4/4 [==============================] - 2s 436ms/step - loss: 0.6977 - binary_accuracy: 0.6407 - val_loss: 0.6780 - val_binary_accuracy: 0.6400\n",
      "Epoch 79/120\n",
      "4/4 [==============================] - 2s 443ms/step - loss: 0.7048 - binary_accuracy: 0.6403 - val_loss: 0.6734 - val_binary_accuracy: 0.6400\n",
      "Epoch 80/120\n",
      "4/4 [==============================] - 2s 430ms/step - loss: 0.7041 - binary_accuracy: 0.6371 - val_loss: 0.6701 - val_binary_accuracy: 0.6400\n",
      "Epoch 81/120\n",
      "4/4 [==============================] - 2s 459ms/step - loss: 0.7025 - binary_accuracy: 0.6381 - val_loss: 0.6672 - val_binary_accuracy: 0.6400\n",
      "Epoch 82/120\n",
      "4/4 [==============================] - 2s 490ms/step - loss: 0.7113 - binary_accuracy: 0.6375 - val_loss: 0.6643 - val_binary_accuracy: 0.6400\n",
      "Epoch 83/120\n",
      "4/4 [==============================] - 2s 470ms/step - loss: 0.7116 - binary_accuracy: 0.6316 - val_loss: 0.6610 - val_binary_accuracy: 0.6400\n",
      "Epoch 84/120\n",
      "4/4 [==============================] - 2s 439ms/step - loss: 0.7080 - binary_accuracy: 0.6389 - val_loss: 0.6581 - val_binary_accuracy: 0.6400\n",
      "Epoch 85/120\n",
      "4/4 [==============================] - 2s 445ms/step - loss: 0.7054 - binary_accuracy: 0.6375 - val_loss: 0.6555 - val_binary_accuracy: 0.6400\n",
      "Epoch 86/120\n",
      "4/4 [==============================] - 2s 419ms/step - loss: 0.7062 - binary_accuracy: 0.6316 - val_loss: 0.6534 - val_binary_accuracy: 0.6400\n",
      "Epoch 87/120\n",
      "4/4 [==============================] - 2s 541ms/step - loss: 0.7018 - binary_accuracy: 0.6445 - val_loss: 0.6518 - val_binary_accuracy: 0.6400\n",
      "Epoch 88/120\n",
      "4/4 [==============================] - 2s 515ms/step - loss: 0.7118 - binary_accuracy: 0.6403 - val_loss: 0.6512 - val_binary_accuracy: 0.6400\n",
      "Epoch 89/120\n",
      "4/4 [==============================] - 2s 446ms/step - loss: 0.7021 - binary_accuracy: 0.6403 - val_loss: 0.6513 - val_binary_accuracy: 0.6400\n",
      "Epoch 90/120\n",
      "4/4 [==============================] - 2s 450ms/step - loss: 0.7049 - binary_accuracy: 0.6382 - val_loss: 0.6514 - val_binary_accuracy: 0.6400\n",
      "Epoch 91/120\n",
      "4/4 [==============================] - 2s 508ms/step - loss: 0.7049 - binary_accuracy: 0.6385 - val_loss: 0.6520 - val_binary_accuracy: 0.6400\n",
      "Epoch 92/120\n",
      "4/4 [==============================] - 2s 470ms/step - loss: 0.7075 - binary_accuracy: 0.6357 - val_loss: 0.6534 - val_binary_accuracy: 0.6400\n",
      "Epoch 93/120\n",
      "4/4 [==============================] - 2s 431ms/step - loss: 0.7093 - binary_accuracy: 0.6430 - val_loss: 0.6549 - val_binary_accuracy: 0.6400\n",
      "Epoch 94/120\n",
      "4/4 [==============================] - 2s 436ms/step - loss: 0.7095 - binary_accuracy: 0.6360 - val_loss: 0.6562 - val_binary_accuracy: 0.6400\n",
      "Epoch 95/120\n",
      "4/4 [==============================] - 2s 529ms/step - loss: 0.7042 - binary_accuracy: 0.6387 - val_loss: 0.6570 - val_binary_accuracy: 0.6400\n",
      "Epoch 96/120\n",
      "4/4 [==============================] - 2s 602ms/step - loss: 0.7039 - binary_accuracy: 0.6331 - val_loss: 0.6579 - val_binary_accuracy: 0.6400\n",
      "Epoch 97/120\n",
      "4/4 [==============================] - 2s 501ms/step - loss: 0.7084 - binary_accuracy: 0.6408 - val_loss: 0.6594 - val_binary_accuracy: 0.6400\n",
      "Epoch 98/120\n",
      "4/4 [==============================] - 2s 448ms/step - loss: 0.7067 - binary_accuracy: 0.6392 - val_loss: 0.6614 - val_binary_accuracy: 0.6400\n",
      "Epoch 99/120\n",
      "4/4 [==============================] - 2s 433ms/step - loss: 0.7030 - binary_accuracy: 0.6404 - val_loss: 0.6633 - val_binary_accuracy: 0.6400\n",
      "Epoch 100/120\n",
      "4/4 [==============================] - 2s 449ms/step - loss: 0.7020 - binary_accuracy: 0.6415 - val_loss: 0.6646 - val_binary_accuracy: 0.6400\n",
      "Epoch 101/120\n",
      "4/4 [==============================] - 2s 467ms/step - loss: 0.7008 - binary_accuracy: 0.6380 - val_loss: 0.6658 - val_binary_accuracy: 0.6400\n",
      "Epoch 102/120\n",
      "4/4 [==============================] - 2s 573ms/step - loss: 0.7009 - binary_accuracy: 0.6319 - val_loss: 0.6668 - val_binary_accuracy: 0.6400\n",
      "Epoch 103/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 542ms/step - loss: 0.7153 - binary_accuracy: 0.6372 - val_loss: 0.6681 - val_binary_accuracy: 0.6400\n",
      "Epoch 104/120\n",
      "4/4 [==============================] - 3s 691ms/step - loss: 0.7026 - binary_accuracy: 0.6441 - val_loss: 0.6691 - val_binary_accuracy: 0.6400\n",
      "Epoch 105/120\n",
      "4/4 [==============================] - 2s 568ms/step - loss: 0.7003 - binary_accuracy: 0.6380 - val_loss: 0.6705 - val_binary_accuracy: 0.6400\n",
      "Epoch 106/120\n",
      "4/4 [==============================] - 2s 507ms/step - loss: 0.6983 - binary_accuracy: 0.6392 - val_loss: 0.6720 - val_binary_accuracy: 0.6400\n",
      "Epoch 107/120\n",
      "4/4 [==============================] - 2s 538ms/step - loss: 0.7073 - binary_accuracy: 0.6365 - val_loss: 0.6733 - val_binary_accuracy: 0.6400\n",
      "Epoch 108/120\n",
      "4/4 [==============================] - 2s 484ms/step - loss: 0.7016 - binary_accuracy: 0.6328 - val_loss: 0.6746 - val_binary_accuracy: 0.6400\n",
      "Epoch 109/120\n",
      "4/4 [==============================] - 2s 528ms/step - loss: 0.7021 - binary_accuracy: 0.6406 - val_loss: 0.6754 - val_binary_accuracy: 0.6400\n",
      "Epoch 110/120\n",
      "4/4 [==============================] - 2s 492ms/step - loss: 0.7056 - binary_accuracy: 0.6387 - val_loss: 0.6762 - val_binary_accuracy: 0.6400\n",
      "Epoch 111/120\n",
      "4/4 [==============================] - 2s 532ms/step - loss: 0.7068 - binary_accuracy: 0.6405 - val_loss: 0.6768 - val_binary_accuracy: 0.6400\n",
      "Epoch 112/120\n",
      "4/4 [==============================] - 2s 508ms/step - loss: 0.7050 - binary_accuracy: 0.6429 - val_loss: 0.6776 - val_binary_accuracy: 0.6400\n",
      "Epoch 113/120\n",
      "4/4 [==============================] - 2s 522ms/step - loss: 0.7034 - binary_accuracy: 0.6334 - val_loss: 0.6787 - val_binary_accuracy: 0.6400\n",
      "Epoch 114/120\n",
      "4/4 [==============================] - 2s 467ms/step - loss: 0.7110 - binary_accuracy: 0.6447 - val_loss: 0.6796 - val_binary_accuracy: 0.6400\n",
      "Epoch 115/120\n",
      "4/4 [==============================] - 2s 433ms/step - loss: 0.7070 - binary_accuracy: 0.6439 - val_loss: 0.6806 - val_binary_accuracy: 0.6400\n",
      "Epoch 116/120\n",
      "4/4 [==============================] - 2s 440ms/step - loss: 0.7048 - binary_accuracy: 0.6370 - val_loss: 0.6816 - val_binary_accuracy: 0.6400\n",
      "Epoch 117/120\n",
      "4/4 [==============================] - 2s 460ms/step - loss: 0.7173 - binary_accuracy: 0.6300 - val_loss: 0.6823 - val_binary_accuracy: 0.6400\n",
      "Epoch 118/120\n",
      "4/4 [==============================] - 2s 428ms/step - loss: 0.7052 - binary_accuracy: 0.6336 - val_loss: 0.6828 - val_binary_accuracy: 0.6400\n",
      "Epoch 119/120\n",
      "4/4 [==============================] - 2s 447ms/step - loss: 0.7046 - binary_accuracy: 0.6325 - val_loss: 0.6832 - val_binary_accuracy: 0.6400\n",
      "Epoch 120/120\n",
      "4/4 [==============================] - 2s 553ms/step - loss: 0.7053 - binary_accuracy: 0.6340 - val_loss: 0.6836 - val_binary_accuracy: 0.6400\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=120, batch_size=2000, validation_split=0.3, callbacks=[callback, tensorboard_cbk, reduce])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fd7e2489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x19d17a4f8e0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = 0\n",
    "loss_values = history.history['loss'][start:]\n",
    "val_loss_values = history.history['val_loss'][start:]\n",
    "epochs = range(start, len(loss_values) + start)\n",
    "plt.plot(epochs, loss_values, 'g', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ec2b60b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "acc_values = history.history['binary_accuracy']\n",
    "val_acc_values = history.history['val_binary_accuracy']\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "plt.plot(epochs, acc_values, 'g', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "plt.title('Training and validation binary_accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('binary_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "201a48da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>direct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.220307</td>\n",
       "      <td>-0.614637</td>\n",
       "      <td>-0.670206</td>\n",
       "      <td>0.178659</td>\n",
       "      <td>-0.313210</td>\n",
       "      <td>0.572237</td>\n",
       "      <td>0.221028</td>\n",
       "      <td>0.020614</td>\n",
       "      <td>-0.612712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574090</td>\n",
       "      <td>-0.164001</td>\n",
       "      <td>0.384716</td>\n",
       "      <td>-0.909016</td>\n",
       "      <td>0.151841</td>\n",
       "      <td>-0.659906</td>\n",
       "      <td>-0.033642</td>\n",
       "      <td>0.319797</td>\n",
       "      <td>1599091200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.698458</td>\n",
       "      <td>-0.199042</td>\n",
       "      <td>-0.370935</td>\n",
       "      <td>0.128899</td>\n",
       "      <td>0.270091</td>\n",
       "      <td>0.030246</td>\n",
       "      <td>0.632135</td>\n",
       "      <td>0.220280</td>\n",
       "      <td>-0.050025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165580</td>\n",
       "      <td>-0.184490</td>\n",
       "      <td>0.246442</td>\n",
       "      <td>-0.184209</td>\n",
       "      <td>0.380183</td>\n",
       "      <td>-0.399366</td>\n",
       "      <td>0.085896</td>\n",
       "      <td>0.361025</td>\n",
       "      <td>1575072000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.486765</td>\n",
       "      <td>0.143920</td>\n",
       "      <td>-0.456979</td>\n",
       "      <td>-0.335641</td>\n",
       "      <td>-0.353965</td>\n",
       "      <td>0.064427</td>\n",
       "      <td>0.452425</td>\n",
       "      <td>0.813212</td>\n",
       "      <td>-0.307713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424229</td>\n",
       "      <td>0.131461</td>\n",
       "      <td>0.704737</td>\n",
       "      <td>-0.229201</td>\n",
       "      <td>-0.000967</td>\n",
       "      <td>-0.695509</td>\n",
       "      <td>0.237292</td>\n",
       "      <td>0.096614</td>\n",
       "      <td>1590192000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.233449</td>\n",
       "      <td>0.497034</td>\n",
       "      <td>-0.244626</td>\n",
       "      <td>-0.010935</td>\n",
       "      <td>-0.139950</td>\n",
       "      <td>-0.222993</td>\n",
       "      <td>0.129606</td>\n",
       "      <td>0.387854</td>\n",
       "      <td>0.429523</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.262688</td>\n",
       "      <td>-0.056827</td>\n",
       "      <td>-0.060793</td>\n",
       "      <td>0.292290</td>\n",
       "      <td>0.133689</td>\n",
       "      <td>-0.552292</td>\n",
       "      <td>0.402135</td>\n",
       "      <td>0.419203</td>\n",
       "      <td>1599955200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.806347</td>\n",
       "      <td>0.100087</td>\n",
       "      <td>-0.147366</td>\n",
       "      <td>0.201620</td>\n",
       "      <td>-0.002529</td>\n",
       "      <td>-0.360041</td>\n",
       "      <td>0.035063</td>\n",
       "      <td>0.109274</td>\n",
       "      <td>-0.185003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308278</td>\n",
       "      <td>-0.098917</td>\n",
       "      <td>0.020196</td>\n",
       "      <td>-0.247934</td>\n",
       "      <td>-0.194947</td>\n",
       "      <td>-0.208917</td>\n",
       "      <td>0.630816</td>\n",
       "      <td>-0.045039</td>\n",
       "      <td>1550966400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>994</td>\n",
       "      <td>-0.248387</td>\n",
       "      <td>0.211109</td>\n",
       "      <td>-0.005984</td>\n",
       "      <td>-0.356238</td>\n",
       "      <td>-0.359684</td>\n",
       "      <td>-0.137757</td>\n",
       "      <td>0.472790</td>\n",
       "      <td>0.507569</td>\n",
       "      <td>-0.664471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111481</td>\n",
       "      <td>-0.577677</td>\n",
       "      <td>0.229019</td>\n",
       "      <td>0.093510</td>\n",
       "      <td>0.016734</td>\n",
       "      <td>-0.525837</td>\n",
       "      <td>0.493276</td>\n",
       "      <td>0.253049</td>\n",
       "      <td>1590796800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>995</td>\n",
       "      <td>-0.768569</td>\n",
       "      <td>0.158932</td>\n",
       "      <td>0.068236</td>\n",
       "      <td>0.299254</td>\n",
       "      <td>-0.486654</td>\n",
       "      <td>-0.087249</td>\n",
       "      <td>0.474589</td>\n",
       "      <td>1.085041</td>\n",
       "      <td>-0.451256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169563</td>\n",
       "      <td>-0.128351</td>\n",
       "      <td>0.471525</td>\n",
       "      <td>-0.023869</td>\n",
       "      <td>-0.274979</td>\n",
       "      <td>-0.709775</td>\n",
       "      <td>0.415889</td>\n",
       "      <td>-0.340360</td>\n",
       "      <td>1596067200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>996</td>\n",
       "      <td>-0.073993</td>\n",
       "      <td>-0.264430</td>\n",
       "      <td>0.154831</td>\n",
       "      <td>0.191368</td>\n",
       "      <td>-0.706662</td>\n",
       "      <td>-0.264844</td>\n",
       "      <td>0.492613</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>-0.136858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057556</td>\n",
       "      <td>-0.173148</td>\n",
       "      <td>0.524388</td>\n",
       "      <td>0.250073</td>\n",
       "      <td>-0.617254</td>\n",
       "      <td>-0.383013</td>\n",
       "      <td>0.137265</td>\n",
       "      <td>0.589417</td>\n",
       "      <td>1571616000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>997</td>\n",
       "      <td>-0.088228</td>\n",
       "      <td>0.037681</td>\n",
       "      <td>-0.163451</td>\n",
       "      <td>0.017490</td>\n",
       "      <td>-0.460612</td>\n",
       "      <td>-0.493232</td>\n",
       "      <td>0.226338</td>\n",
       "      <td>0.490925</td>\n",
       "      <td>0.108212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117323</td>\n",
       "      <td>0.126527</td>\n",
       "      <td>-0.189481</td>\n",
       "      <td>-0.155586</td>\n",
       "      <td>-0.077713</td>\n",
       "      <td>-0.237214</td>\n",
       "      <td>0.212463</td>\n",
       "      <td>0.376480</td>\n",
       "      <td>1574294400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>998</td>\n",
       "      <td>-0.608430</td>\n",
       "      <td>0.099852</td>\n",
       "      <td>0.042408</td>\n",
       "      <td>0.207803</td>\n",
       "      <td>-0.323645</td>\n",
       "      <td>-0.641098</td>\n",
       "      <td>0.160955</td>\n",
       "      <td>0.628198</td>\n",
       "      <td>-0.101303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081059</td>\n",
       "      <td>-0.291444</td>\n",
       "      <td>0.378666</td>\n",
       "      <td>0.091121</td>\n",
       "      <td>-0.419978</td>\n",
       "      <td>-0.456431</td>\n",
       "      <td>0.022081</td>\n",
       "      <td>0.550155</td>\n",
       "      <td>1593388800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9990 rows × 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0         0         1         2         3         4         5  \\\n",
       "0              0 -1.220307 -0.614637 -0.670206  0.178659 -0.313210  0.572237   \n",
       "1              1 -0.698458 -0.199042 -0.370935  0.128899  0.270091  0.030246   \n",
       "2              2 -0.486765  0.143920 -0.456979 -0.335641 -0.353965  0.064427   \n",
       "3              3 -0.233449  0.497034 -0.244626 -0.010935 -0.139950 -0.222993   \n",
       "4              4 -0.806347  0.100087 -0.147366  0.201620 -0.002529 -0.360041   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "9985         994 -0.248387  0.211109 -0.005984 -0.356238 -0.359684 -0.137757   \n",
       "9986         995 -0.768569  0.158932  0.068236  0.299254 -0.486654 -0.087249   \n",
       "9987         996 -0.073993 -0.264430  0.154831  0.191368 -0.706662 -0.264844   \n",
       "9988         997 -0.088228  0.037681 -0.163451  0.017490 -0.460612 -0.493232   \n",
       "9989         998 -0.608430  0.099852  0.042408  0.207803 -0.323645 -0.641098   \n",
       "\n",
       "             6         7         8  ...       760       761       762  \\\n",
       "0     0.221028  0.020614 -0.612712  ...  0.574090 -0.164001  0.384716   \n",
       "1     0.632135  0.220280 -0.050025  ...  0.165580 -0.184490  0.246442   \n",
       "2     0.452425  0.813212 -0.307713  ...  0.424229  0.131461  0.704737   \n",
       "3     0.129606  0.387854  0.429523  ... -0.262688 -0.056827 -0.060793   \n",
       "4     0.035063  0.109274 -0.185003  ...  0.308278 -0.098917  0.020196   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "9985  0.472790  0.507569 -0.664471  ...  0.111481 -0.577677  0.229019   \n",
       "9986  0.474589  1.085041 -0.451256  ...  0.169563 -0.128351  0.471525   \n",
       "9987  0.492613  0.639175 -0.136858  ...  0.057556 -0.173148  0.524388   \n",
       "9988  0.226338  0.490925  0.108212  ...  0.117323  0.126527 -0.189481   \n",
       "9989  0.160955  0.628198 -0.101303  ...  0.081059 -0.291444  0.378666   \n",
       "\n",
       "           763       764       765       766       767   timestamp  direct  \n",
       "0    -0.909016  0.151841 -0.659906 -0.033642  0.319797  1599091200       1  \n",
       "1    -0.184209  0.380183 -0.399366  0.085896  0.361025  1575072000       0  \n",
       "2    -0.229201 -0.000967 -0.695509  0.237292  0.096614  1590192000       1  \n",
       "3     0.292290  0.133689 -0.552292  0.402135  0.419203  1599955200       0  \n",
       "4    -0.247934 -0.194947 -0.208917  0.630816 -0.045039  1550966400       1  \n",
       "...        ...       ...       ...       ...       ...         ...     ...  \n",
       "9985  0.093510  0.016734 -0.525837  0.493276  0.253049  1590796800       1  \n",
       "9986 -0.023869 -0.274979 -0.709775  0.415889 -0.340360  1596067200       1  \n",
       "9987  0.250073 -0.617254 -0.383013  0.137265  0.589417  1571616000       0  \n",
       "9988 -0.155586 -0.077713 -0.237214  0.212463  0.376480  1574294400       0  \n",
       "9989  0.091121 -0.419978 -0.456431  0.022081  0.550155  1593388800       0  \n",
       "\n",
       "[9990 rows x 771 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(f'{folder}/cls_direct30_19.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "63baacf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.1463730e-01, -6.7020565e-01,  1.7865859e-01, ...,\n",
       "        -3.3641793e-02,  3.1979680e-01,  1.5990912e+09],\n",
       "       [-1.9904244e-01, -3.7093472e-01,  1.2889920e-01, ...,\n",
       "         8.5896015e-02,  3.6102468e-01,  1.5750720e+09],\n",
       "       [ 1.4391986e-01, -4.5697948e-01, -3.3564094e-01, ...,\n",
       "         2.3729247e-01,  9.6614200e-02,  1.5901920e+09],\n",
       "       ...,\n",
       "       [-2.6443022e-01,  1.5483065e-01,  1.9136800e-01, ...,\n",
       "         1.3726503e-01,  5.8941680e-01,  1.5716160e+09],\n",
       "       [ 3.7680700e-02, -1.6345091e-01,  1.7490165e-02, ...,\n",
       "         2.1246300e-01,  3.7647970e-01,  1.5742944e+09],\n",
       "       [ 9.9851586e-02,  4.2408280e-02,  2.0780262e-01, ...,\n",
       "         2.2081050e-02,  5.5015457e-01,  1.5933888e+09]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.array(test.iloc[:,2:770])\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f5b1e98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np.array(test['direct'])\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cb811f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6517\n",
      "[0.6736859679222107, 0.6516516804695129]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1735d8fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "315ad4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9990\n",
       "Name: direct, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "predictions_df = pd.DataFrame()\n",
    "predictions_df['direct'] = [1 if val > threshold else 0 for val in predictions]\n",
    "predictions_df['direct'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e1999638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c488f5e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 653 2201]\n",
      " [2827 4309]]\n",
      "0.4966966966966967\n"
     ]
    }
   ],
   "source": [
    "#print(roc_auc_score(predictions_df['direct'], y_test))\n",
    "print(confusion_matrix(predictions_df['direct'], y_test))\n",
    "print(accuracy_score(predictions_df['direct'], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be852984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f1403d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'C': 0.0001}\n",
      "best scrores:  0.5456493530567604\n",
      "Wall time: 3h 21min 40s\n",
      "Parser   : 174 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parameters = {'C': np.linspace(0.0001, 100, 20)}\n",
    "grid_search = GridSearchCV(LogisticRegression(solver=\"saga\"), parameters)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "print('best parameters: ', grid_search.best_params_)\n",
    "print('best scrores: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2c12a5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14min 28s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0001, solver='saga')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf = LogisticRegression(solver=\"saga\", C=0.0001)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a63ffaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5528028028028028"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3e5a0a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier score: 0.652 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf_dummy = DummyClassifier()\n",
    "\n",
    "scores = cross_val_score(clf_dummy, x_test, y_test)\n",
    "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "10e6f387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94947fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf = RandomForestRegressor(n_estimators = 1000)\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0bf043",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf.predict(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
